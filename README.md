# IndiaCode Web Crawler

A modular and production-ready web crawler for [https://www.indiacode.nic.in/](https://www.indiacode.nic.in/), designed to recursively collect and download legal documents.

---

## ğŸš€ Features

- Recursive link crawling with depth control
- Filtering of document filetypes (PDF, DOCX, etc.)
- Parallel downloading with batch control
- Logging of successes and failures
- Metadata export in CSV
- Command-line arguments for full configurability

---

## ğŸ–¼ Output Preview

### ğŸ“ Downloaded Files
All documents are saved in the `downloads/` folder:

![Downloads folder](assets/downloads_folder.png)

---

### ğŸ“„ Extracted Document Links
Saved as `document_links.csv`:

![Document links CSV](assets/document_links_csv.png)

---

### ğŸ“ Metadata Export
CSV of downloaded documents and metadata:

![Metadata CSV](assets/metadata_csv.png)

---

### ğŸ§¾ Scraper Log
Log of progress and errors:

![Scraper log](assets/scraper_log.png)

---

## âš™ï¸ Usage

```bash
python main.py ^
  --base-url "https://www.indiacode.nic.in/" ^
  --max-depth 2 ^
  --max-files 100 ^
  --batch-size 5 ^
  --export-csv "document_links.csv" ^
  --download-path "downloads" ^
  --failed-log "failed_urls.csv"
```

---

## ğŸ—‚ Folder Structure

```
IndiaCode/
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ crawler.py
â”‚   â”œâ”€â”€ downloader.py
â”‚   â””â”€â”€ ...
â”œâ”€â”€ downloads/
â”œâ”€â”€ metadata/
â”œâ”€â”€ logs/
â”œâ”€â”€ assets/
â”‚   â”œâ”€â”€ downloads_folder.png
â”‚   â”œâ”€â”€ document_links_csv.png
â”‚   â”œâ”€â”€ metadata_csv.png
â”‚   â””â”€â”€ scraper_log.png
â””â”€â”€ README.md
```

---

## ğŸ“¬ Author

Martin Votava  
ğŸ”— [github.com/Martin-vot](https://github.com/Martin-vot)  
ğŸ“§ [martin@example.com](mailto:martin@example.com) (vymÄ›Åˆ za svÅ¯j email nebo smaÅ¾)

---
